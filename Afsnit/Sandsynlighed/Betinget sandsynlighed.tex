Hvis man har ekstra information om en given hændelse, så vil udfaldsrummet indskrænkes - mere formelt:\\
\begin{minipage}\textwidth
\begin{defn}\textbf{Betinget sandsynlighed} %Ny definition
\newline
Lad $B$ være en hændelse sådan at $P(B)>0$. Den \textit{betingede sandsynlighed} af $A$ givet $B$ er defineret som
\begin{align*}
      \displaystyle P(A|B)=\frac{P(A\cap B)}{P(B)}
\end{align*}
\end{defn}
\end{minipage}

\subsection{Uafhængige hændelser}
Hvis to hændelser, $A$ og $B$, er \textit{uafhængige}, vil en betingelse $B$ ikke påvirke sandsynligheden for $A$. Med andre ord, så er den betingede og ubetingede sandsynlighed den samme. Dette har konsekvensen, at $P(A)=P(A|B)\Leftrightarrow P(A\cap B)=P(A)P(B)$. Faktisk kan dette generaliseres til følgende definition:\\
\begin{minipage}\textwidth
\begin{defn}\textbf{Uafhængighed} %Ny definition
\newline
Hændelserne, $A_1,A_2,\dots$ siges at være uafhængige hvis
\begin{align*}
    P(A_{i_1}\cap A_{i_2}\cap\cdots\cap A_{i_k})=P(A_{i_1})P(A_{i_2})\cdots P(A_{i_k})
\end{align*}
for alle følger af heltal, $i_1<i_2<\cdots<i_k, k=2,3,\dots$.
Hvis de ikke er uafhængige er \textit{afhængige}.
\end{defn}
\end{minipage}
\subsection{Total sandsynlighed}
I tilfælde af, at sandsynligheden for en given hændelse er svær at bestemme direkte kan det i nogle tilfælde være hensigtsmæssigt at opdele problemet i termer af betinget sandsynlighed.



\begin{minipage}\textwidth
\begin{thmx} \textbf{Loven om Total Sandsynlighed} \label{sæt:loven_om_total_sandsynlighed} %Ny sætning
\newline
Lad $B_1,B_2,\dots$ være en følge af hændelser, sådan at
\begin{enumerate}[label=(\textbf{\alph*})]
\item $P(B_k)>0$ for $k=1,2,\dots$
\item $B_i$ og $B_j$ er disjunkte når $i\neq j$
\item $S=\bigcup_{k=1}^\infty B_k$
\end{enumerate}
Så for enhver hændelse, $A$ gælder der, at
\begin{align*}
    P(A)=\sum_{k=1}^\infty P(A|B_k)P(B_k)
\end{align*}
\end{thmx}
\end{minipage}
\begin{bev} \textbf{} %Nyt bevis
\newline
Bemærk, at
\begin{align*}
    A=A\cap S=\bigcup_{k=1}^\infty(A\cap B_k)
\end{align*}
i henhold til den distributive lov for uendelige foreningsmængder (se Bilag \ref{Distributive love}). 
Eftersom $A\cap B_1,A\cap B_2,\dots$ er parvis disjunkte fås
\begin{align*}
    P(A)=\sum_{k=1}^\infty P(A\cap B_k)=\sum_{k=1}^\infty P(A|B_k)P(B_k)
\end{align*}
\end{bev}
%By virtue of Proposition 1.2, we realize that the law of total probability is also true for a finite union of events
%Hvis mængden af hændelser er endelig og givet ved $n$, kan man konstruere en uendelig følge af hændelser, sådan at P(\bigcup_{k=n}^\infty B_k)=0.
For $n=2$ gælder der, at hvis $B_1=B$, så følger det at $B_2=B^c$ og følgende korollar fås.
\begin{minipage}\textwidth
\begin{kor} \textbf{} %Nyt korollar
\newline
Hvis $0<P(B)<1$, så er
\begin{align*}
    P(A)=P(A|B)P(B)+P(A|B^c)P(B^c)
\end{align*}
\end{kor}
\end{minipage}
\iffalse
Idét foreningsmængder er kommutative, gælder der, at
$$P(B_j|A)P(A)=P(A|B_j)P(B_j)$$
som må betyde, at
$$P(B_j|A)=\frac{P(A|B_j)P(B_j)}{P(A)}$$

Dette leder op til følgende proposition:\\
\begin{minipage}\textwidth
\begin{pro} \textbf{(Bayes' Formel).} %Ny proposition
\newline
Med samme antagelser som i Loven om Total Sandsynlighed og hvis $P(A)>0$, så gælder der for enhver hændelse, $B_j$, at
\begin{align*}
    P(B_j|A)=\frac{P(A|B_j)P(B_j)}{\sum_{k=1}^\infty P(A|B_k)P(B_k)}
\end{align*}
\end{pro}
\end{minipage}
\begin{bev}
Beviset følger af foregående udregninger.
\end{bev}

Analogt, følger denne korrollar:\\
\begin{minipage}\textwidth
\begin{kor} \textbf{} %Nyt korollar
\newline
Hvis $0<P(B)<1$ og $P(A)>0$, så er
\begin{align*}
    P(B|A)=\frac{P(A|B)P(B)}{P(A|B)P(B)+P(A|B^c)P(B^c)}
\end{align*}
\end{kor}
\end{minipage}
\fi